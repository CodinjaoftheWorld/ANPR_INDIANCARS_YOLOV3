{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANPR_IndianCars_Yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDJ_ulDi5FI"
      },
      "source": [
        "# **Step 1: Prepare the dataset**\n",
        "\n",
        "a . Get the images of Indian Cars with number plate.\n",
        "Create 2 folders 'test' and 'train' and trandfer 30% of the images in test and 70% images in train folders respectively.\n",
        "\n",
        "Alternatively, you can use the test and train data used by me for training.\n",
        "test and train folders with annotation files are attached to this repository.\n",
        "\n",
        "\n",
        "These activities should to be performed manually. For more details please refer the article link -  \n",
        "\n",
        "\n",
        "b. Label the licence plates in all the images in respective test and train folders, using LabelImg and generate the annoted .xml file for the images within the respective folders.\n",
        "You can get more details on LabelImg from [here](https://github.com/tzutalin/labelImg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25dGJ2aAjF4m"
      },
      "source": [
        "# **Step 2: Prepare the dataset**\n",
        "\n",
        "Download YOLOv3 project\n",
        "\n",
        "`! git clone https://github.com/AlexeyAB/darknet`\n",
        "\n",
        "\n",
        "Open darknet/Makefile and put 1 infront of GPU, CUDNN and OPENCV, instead of 0.\n",
        " \n",
        "These changes are required if you wanted to use GPU on google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xZmRae9UCGG"
      },
      "source": [
        "# **Step 3: Installing the base darknet system**\n",
        "\n",
        "Install the base darknet framework with the below commands.\n",
        "\n",
        "```\n",
        "! cd darknet\n",
        "! make\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZThhdZWfUcz0"
      },
      "source": [
        "# **Step 4: Upload images in Google Colab and generate YOLO compatible annotation files.**\n",
        "\n",
        "\n",
        "a. Mount the Google Drive\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "cd /content/gdrive/MyDrive\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "b. Upload test and train folders in darknet folder within Google Colab. (For this step, use images present in the test and train folders) \n",
        "\n",
        "c. To convert the bounding box coordinates from the .xml file to the .txt file(YOLO compatible) run the following commands.\n",
        "\n",
        "```\n",
        "! cd darknet\n",
        "! python convert.py\n",
        "```\n",
        "\n",
        "This step will pick the coordinates from the .xml file and put them into YOLO compatible .txt file in the same directories as images. Also, train.txt and test.txt files are created within the darknet folder, containing the location of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gObKcROVGHP"
      },
      "source": [
        "# **Step 5: Prepare custom 'my_data' folder**\n",
        "\n",
        "a. Run the below command to make a custome folder named 'my_data'\n",
        "```\n",
        "! mkdir my_data\n",
        "```\n",
        "b. Move the train.txt and test.txt files from the darknet directory to my_data directory.\n",
        "```\n",
        "! mv train.txt my_data/\n",
        "! mv test.txt my_data/\n",
        "```\n",
        "c. Create classes.names file within my_data directory with class name as \"LP\".\n",
        "```\n",
        "! touch darknet/my_data/classes.names\n",
        "! echo LP > classes.names\n",
        "```\n",
        "d. Create weights directory within my_data directory.\n",
        "```\n",
        "! mkdir my_data/weights\n",
        "```\n",
        "e. Create file darknet.data within my_data directory to provide the configuration details.\n",
        "```\n",
        "! touch darknet/my_data/darknet.data\n",
        "```\n",
        "\n",
        "Paste the below details in darknet.data file.\n",
        "*   classes = 1\n",
        "*   train  = my_data/train.txt\n",
        "*   valid  = my_data/test.txt\n",
        "*   names = my_data/classes.names\n",
        "*   backup = my_data/weights/\n",
        "\n",
        "f. Copy and Paste the cfg file from darknet/cfg/yolov3.cfg to darknet/my_data directory.\n",
        "```\n",
        "! cp   darknet/cfg/yolov3.cfg to darknet/my_data\n",
        "```\n",
        "\n",
        "Make the following changes in yolov3.cfg in my_data directory\n",
        "*   Line 603, 693, and 780 change the filters to 18. (filters = (classes + 5) * 3). In our case we are detecting only 1 class, so the number of filters will be equal to 18.\n",
        "\n",
        "*   Line 783, change the number of classes to 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7yNTZlSkv1g"
      },
      "source": [
        "# **Step 6: Download the initial yolo weights for training the custom data**\n",
        "\n",
        "\n",
        "Run the following command from the darknet directory.\n",
        "```\n",
        "! wget https://pjreddie.com/media/files/darknet53.conv.74\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHiAguXnlNKZ"
      },
      "source": [
        "# **Step 7: Set criteria to save the weights file in weights directory**\n",
        "\n",
        "Open detector.c file from darknet/examples directory and change line number 138 as shown below.\n",
        "```\n",
        "if(i%1000==0 || (i < 1000 && i%200 == 0))\n",
        "```\n",
        "This change saves the weight in my_data/weights directory for every 200th iteration till 1000 iterations and then for every 1000th iteration. For the demonstration, I have trained this model for 8000 iterations only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDOAKg23ly9O"
      },
      "source": [
        "# **Step 8: Now start the training**\n",
        "\n",
        "Run the follwoing command from the darknet directory.\n",
        "```\n",
        "! ./darknet detector train my_data/darknet.data my_data/yolov3.cfg darknet53.conv.74\n",
        "```\n",
        "Note: In case you get \"/bin/bash: ./darknet: Permission denied\" error then run the below command and then run the above command.\n",
        "```\n",
        "! chmod +x darknet\n",
        "```\n",
        "\n",
        "Note: \n",
        "You might not be able to train the model in one shot due to restictions in google colab.\n",
        "Check the lastest weight stored in my_data/weights folder and then train the model again with the updated weights. In case you have yolov3_8000.weights in your weights folder then run the below command to train the model again with new weights.\n",
        "```\n",
        "! ./darknet detector train my_data/darknet.data my_data/yolov3.cfg /content/gdrive/MyDrive/darknet/my_data/weights/yolov3_8000.weights\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBpBbKAXwbBO"
      },
      "source": [
        "# **Step 8: Detect and Blur the Licence Plate from the image**\n",
        "\n",
        "Change the weightsPath in line number 12 and the image file name in line number 15 before running the below code.\n",
        "\n",
        "You should see the image of a car with the detection and blurred number plate.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "CONF_THRESH, NMS_THRESH = 0.5, 0.5\n",
        "\n",
        "weightsPath = 'my_data/weights/yolov3_8000.weights'\n",
        "configPath = 'my_data/yolov3.cfg'\n",
        "namesPath = 'my_data/classes.names'\n",
        "image = 'images8.jpg'\n",
        "\n",
        "# Load the network using openCV\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "# Get the output layer from YOLOv3\n",
        "layers = net.getLayerNames()\n",
        "output_layers = [layers[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Read and convert the image to blob and perform forward pass\n",
        "img = cv2.imread(image)\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "height, width = img.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "layer_outputs = net.forward(output_layers)\n",
        "\n",
        "class_ids, confidences, b_boxes = [], [], []\n",
        "for output in layer_outputs:\n",
        "for detection in output:\n",
        "scores = detection[5:]\n",
        "class_id = np.argmax(scores)\n",
        "confidence = scores[class_id]\n",
        "\n",
        "if confidence > CONF_THRESH:\n",
        "center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
        "\n",
        "x = int(center_x - w / 2)\n",
        "y = int(center_y - h / 2)\n",
        "\n",
        "b_boxes.append([x, y, int(w), int(h)])\n",
        "confidences.append(float(confidence))\n",
        "class_ids.append(int(class_id))\n",
        "\n",
        "# Perform non maximum suppression for the bounding boxes to filter overlapping and low confident bounding boxes\n",
        "indices = cv2.dnn.NMSBoxes(b_boxes, confidences, CONF_THRESH, NMS_THRESH).flatten().tolist()\n",
        "\n",
        "if len(indices) > 0:\n",
        "\n",
        "# Draw the filtered bounding boxes with their class to the image\n",
        "with open(namesPath, \"r\") as f:\n",
        "classes = [line.strip() for line in f.readlines()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "for index in indices:\n",
        "(x,y) = (b_boxes[index][0], b_boxes[index][1])\n",
        "(w,h) = (b_boxes[index][2], b_boxes[index][3])\n",
        "# Blur the ROI of the detected licence plate \n",
        "img[y:y+h, x:x+w] = cv2.GaussianBlur(img[y:y+h, x:x+w] ,(35,35),0)\n",
        "\n",
        "cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "text = \"{}: {:.4f}\".format(\"LP\", confidences[index])\n",
        "cv2.putText(img, text, (x, y - 3), cv2.FONT_HERSHEY_COMPLEX_SMALL, .75 , (0, 255, 0), 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "```"
      ]
    }
  ]
}