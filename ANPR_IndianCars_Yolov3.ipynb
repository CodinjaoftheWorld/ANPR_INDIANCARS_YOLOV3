{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ANPR_IndianCars_Yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HAaavQRKBMy"
      },
      "source": [
        "# License Plate Detection on Indian Cars using YOLOv3 and Blurring of License Plates\n",
        "\n",
        "This repository guides you through the steps for annotating and training a custom model to detect and blur the license plates on Indian cars.\n",
        "\n",
        "Please follow the associated article for more details - https://medium.com/@gauravsaini.728/license-plate-detection-on-indian-cars-using-yolov3-and-blurring-of-license-plates-9f2a24d48f04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp7X-4vW6OpZ"
      },
      "source": [
        "# Step 1: Prepare the dataset\n",
        "\n",
        "a. Get the images of Indian Cars with the number plate. Create 2 folders 'test' and 'train' and transfer 20% of the images in test and 80% images in train folders respectively.\n",
        "\n",
        "Alternatively, you can use the test and train data used by me for training. Download test.zip and train.zip files from this Github Repository for accessing the annotated images.\n",
        "\n",
        "b. Annotate the license plates in all the images in the respective test and train folders, using LabelImg, and generate the annotated .xml file for the images within the respective folders. You can get more details on LabelImg from [here\n",
        "](https://github.com/tzutalin/labelImg).(Conversion process is mentioned in step 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5_UIvTs7OvH"
      },
      "source": [
        "# Step 2: Installing the base darknet system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9gfWSIl7KCT"
      },
      "source": [
        "# Mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J65RR0Wp7kCf"
      },
      "source": [
        "# Navigate to MyDrive\n",
        "%cd /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6nAqAPL9MgR"
      },
      "source": [
        "# Download YOLOv3 project\n",
        "! git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTscV_6P8ToS"
      },
      "source": [
        "# Install the base darknet framework\n",
        "%cd darknet\n",
        "! make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0evHLMDB44Z"
      },
      "source": [
        "# Uplod test and train directories in the darknet directory along with the convert.py file from this respository and run the below command\n",
        "# This step will pick the coordinates from each .xml file and put them into YOLO compatible .txt file in the same test and train directories.\n",
        " # Also, train.txt and test.txt files are created within the darknet folder, containing the location of images.\n",
        " \n",
        "! python convert.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bysCNUhpC0eF"
      },
      "source": [
        "# Step 4: Prepare custom 'my_data' folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_zSaIFCEBk"
      },
      "source": [
        "# Run the below command to make a custom folder named 'my_data'\n",
        "! mkdir my_data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8CBMydTC6N2"
      },
      "source": [
        "# Move the train.txt and test.txt files from the darknet directory to the my_data directory.\n",
        "! mv train.txt my_data/ \n",
        "! mv test.txt my_data/"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjoLs0cKDJkp"
      },
      "source": [
        "# Create classes.names file within my_data directory with class name as \"LP\"\n",
        "! touch /content/gdrive/MyDrive/darknet/my_data/classes.names \n",
        "! echo LP > /content/gdrive/MyDrive/darknet/my_data/classes.names"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOu0cR-DDQVV"
      },
      "source": [
        "# Create weights directory within the my_data directory\n",
        "! mkdir my_data/weights"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbRVcxVlEJ8z"
      },
      "source": [
        "# Create file darknet.data within my_data directory to provide the configuration details\n",
        "! touch /content/gdrive/MyDrive/darknet/my_data/darknet.data\n",
        "\n",
        "# Paste the below details manually in darknet.data file\n",
        "## classes = 1\n",
        "## train = my_data/train.txt\n",
        "## valid = my_data/test.txt\n",
        "## names = my_data/classes.names\n",
        "## backup = my_data/weights/"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtzTT1aIG26H"
      },
      "source": [
        "# Copy and Paste the cfg file from darknet/cfg/yolov3.cfg to darknet/my_data directory\n",
        "! cp /content/gdrive/MyDrive/darknet/cfg/yolov3.cfg /content/gdrive/MyDrive/darknet/my_data\n",
        "\n",
        "# Make the following changes in yolov3.cfg in my_data directory.\n",
        "# Line 603, 693, and 780 change the filters to 18. (filters = (classes + 5) * 3). \n",
        "#In our case we are detecting only 1 class, so the number of filters will be equal to 18.\n",
        "# Line 783, change the number of classes to 1."
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaVsTPPkIVro"
      },
      "source": [
        "# **Step 5: Download the initial yolo weights for training the custom data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-xYWSasIW5C"
      },
      "source": [
        "# Run the following command from the darknet directory\n",
        "! wget https://pjreddie.com/media/files/darknet53.conv.74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBf9BkL2IneA"
      },
      "source": [
        "## Step 6: Set criteria to save the weights file in the weights **directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLg01QFuIoss"
      },
      "source": [
        "# Open detector.c file from darknet/examples directory and change line number 138 as shown below.\n",
        "\n",
        "if(i%1000==0 || (i < 1000 && i%200 == 0))\n",
        "\n",
        "# This change saves the weight in my_data/weights directory for every 200th iteration till 1000 iterations and then for every 1000th iteration."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBYdMlf-I4v-"
      },
      "source": [
        "## Step 7: Now start the **training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pT7qzmCI5pa"
      },
      "source": [
        "# Run the following command from the darknet directory\n",
        "! ./darknet detector train /content/gdrive/MyDrive/darknet/my_data/darknet.data /content/gdrive/MyDrive/darknet/my_data/yolov3.cfg /content/gdrive/MyDrive/darknet/darknet53.conv.74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmfBDJyzJkaN"
      },
      "source": [
        "## Step 8: Detect and Blur the Licence Plate from the **image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X02AWj2CJmWo"
      },
      "source": [
        "# Change the weightsPath in line number 12 and the image file name in line number 15 before running the below code\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "CONF_THRESH, NMS_THRESH = 0.5, 0.5\n",
        "\n",
        "\n",
        "weightsPath = 'custom/weights/yolov3_8000.weights'\n",
        "configPath = 'custom/yolov3.cfg'\n",
        "namesPath = 'custom/classes.names'\n",
        "image = 'img3.jpeg'\n",
        "\n",
        "# Load the network using openCV\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "# Get the output layer from YOLOv3\n",
        "layers = net.getLayerNames()\n",
        "output_layers = [layers[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "\n",
        "# Read and convert the image to blob and perform forward pass\n",
        "img = cv2.imread(image)\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "height, width = img.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "layer_outputs = net.forward(output_layers)\n",
        "\n",
        "\n",
        "class_ids, confidences, b_boxes = [], [], []\n",
        "for output in layer_outputs:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > CONF_THRESH:\n",
        "            center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
        "\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            b_boxes.append([x, y, int(w), int(h)])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(int(class_id))\n",
        "\n",
        "\n",
        "# Perform non maximum suppression for the bounding boxes to filter overlapping and low confident bounding boxes\n",
        "indices = cv2.dnn.NMSBoxes(b_boxes, confidences, CONF_THRESH, NMS_THRESH).flatten().tolist()\n",
        "\n",
        "if len(indices) > 0:\n",
        "\n",
        "    # Draw the filtered bounding boxes with their class to the image\n",
        "    with open(namesPath, \"r\") as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "    for index in indices:\n",
        "        (x,y) = (b_boxes[index][0], b_boxes[index][1])\n",
        "        (w,h) = (b_boxes[index][2], b_boxes[index][3])\n",
        "        \n",
        "        # Blur the ROI of the detected licence plate \n",
        "        img[y:y+h, x:x+w] = cv2.GaussianBlur(img[y:y+h, x:x+w] ,(35,35),0)\n",
        "\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        text = \"{}: {:.4f}\".format(\"LP\", confidences[index])\n",
        "        cv2.putText(img, text, (x, y - 3), cv2.FONT_HERSHEY_COMPLEX_SMALL, .75 , (0, 255, 0), 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
